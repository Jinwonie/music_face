{"cells":[{"cell_type":"markdown","source":["해당 코드는 로컬 PC에서 작성 및 실행한 코드입니다.   \n","각 팀원이 동시에 여러 모델을 학습시키는 과정에서   \n","YOLO, Mobilenet, Inceoption 모델은 로컬 PC를 사용하게 되었습니다.   \n","   \n","사용한 파이썬 버전과 라이브러리 목록입니다.   \n","python : 3.10.0   \n","tensorflow : 2.10.0   \n","tensorflow-gpu : 2.10.0   "],"metadata":{"id":"pwtkMnodKZUi"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"qUWyEmkiiplX"},"outputs":[],"source":["# tensorflow gpu 사용하도록 설정\n","import os\n","import tensorflow as tf\n","\n","os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n","gpus = tf.config.experimental.list_physical_devices('GPU')\n","if gpus:\n","    try:\n","        tf.config.experimental.set_memory_growth(gpus[0], True)\n","    except RuntimeError as e:\n","        print(e)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KHcck39eiplZ"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications import MobileNetV2\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import LearningRateScheduler\n","import math\n","\n","# 데이터 경로\n","train_dir = 'C:/Users/handt/Desktop/finalpjt data/preprocessed_crop/train'\n","validation_dir = 'C:/Users/handt/Desktop/finalpjt data/preprocessed_crop/val'\n","\n","# 이미지 데이터 전처리\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,  # 픽셀 값을 0-1 사이로 정규화\n","    rotation_range=40,  # 이미지를 랜덤으로 회전\n","    width_shift_range=0.3,  # 이미지를 수평으로 랜덤 이동\n","    height_shift_range=0.3,  # 이미지를 수직으로 랜덤 이동\n","    shear_range=0.3,  # 이미지를 랜덤으로 시어 변환\n","    zoom_range=0.3,  # 이미지를 랜덤으로 확대/축소\n","    horizontal_flip=True,  # 이미지를 수평으로 랜덤 플립\n","    vertical_flip=True,  # 이미지를 수직으로 랜덤 플립\n","    fill_mode='nearest')  # 변환 후 빈 공간을 채우는 방식\n","\n","validation_datagen = ImageDataGenerator(rescale=1./255)  # 검증 데이터, 정규화만 사용\n","\n","# 데이터 로드\n","train_generator = train_datagen.flow_from_directory(\n","    train_dir,\n","    target_size=(224, 224),\n","    batch_size=16,\n","    class_mode='categorical')\n","\n","validation_generator = validation_datagen.flow_from_directory(\n","    validation_dir,\n","    target_size=(224, 224),\n","    batch_size=16,\n","    class_mode='categorical')\n","\n","# 클래스 이름 보여주기\n","print(\"클래스 이름 (train):\", train_generator.class_indices)\n","print(\"클래스 이름 (validation):\", validation_generator.class_indices)\n","\n","# MobileNetV2 모델 로드\n","base_model = MobileNetV2(input_shape=(224, 224, 3),  # 입력 이미지 형태\n","                         include_top=False,  # 최상위 분류 층 제외\n","                         weights='imagenet')  # ImageNet 사전 학습 가중치 사용\n","\n","# 모델 맞춤화\n","x = base_model.output  # 기본 모델의 출력\n","x = GlobalAveragePooling2D()(x)  # 전역 평균 풀링 층 추가\n","x = BatchNormalization()(x)  # 배치 정규화 층 추가\n","x = Dense(1024, activation='relu')(x)  # 완전 연결 층 추가\n","x = Dropout(0.5)(x)  # 드롭아웃 층 추가\n","x = Dense(512, activation='relu')(x)  # 추가 완전 연결 층\n","x = Dropout(0.5)(x)  # 드롭아웃 층 추가\n","predictions = Dense(len(train_generator.class_indices), activation='softmax')(x)  # 출력 층, 클래스 수 만큼 뉴런 설정\n","\n","model = Model(inputs=base_model.input, outputs=predictions)  # 전체 모델 정의\n","\n","# 일부 상위 레이어를 학습 가능하게 설정\n","base_model.trainable = True  # 기본 모델의 모든 층을 학습 가능하게 설정\n","fine_tune_at = 50  # 상위 50개 레이어를 제외한 나머지 레이어를 학습 가능하게 설정\n","for layer in base_model.layers[:fine_tune_at]:\n","    layer.trainable = False  # 하위 50개 레이어는 학습 불가능하게 설정\n","\n","# 학습률 스케줄링 함수 정의\n","def scheduler(epoch, lr):\n","    if epoch < 10:\n","        return lr  # 초기 10 에포크 동안 학습률 유지\n","    else:\n","        return lr * math.exp(-0.1)  # 이후 학습률 감소\n","\n","callback = LearningRateScheduler(scheduler)  # 학습률 스케줄링 콜백\n","\n","# 모델 컴파일\n","model.compile(optimizer=Adam(learning_rate=1e-4),  # Adam 옵티마이저와 학습률 설정\n","              loss='categorical_crossentropy',  # 손실 함수 설정\n","              metrics=['accuracy'])  # 평가 지표 설정\n","\n","# 모델 학습\n","history = model.fit(\n","    train_generator,\n","    steps_per_epoch=train_generator.samples // train_generator.batch_size,  # 에포크당 스텝 수\n","    epochs=30,\n","    validation_data=validation_generator,\n","    validation_steps=validation_generator.samples // validation_generator.batch_size,  # 검증 스텝 수\n","    callbacks=[callback])\n","\n","# 모델 평가\n","model.evaluate(validation_generator)  # 검증 데이터로 모델 평가\n","\n","model.save('saved_model_mobilenetv2_improved.h5')  # 모델 저장\n"]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications import MobileNetV3Large\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau\n","import math\n","\n","# 데이터 경로\n","train_dir = 'C:/Users/handt/Desktop/finalpjt data/preprocessed_crop/train'\n","validation_dir = 'C:/Users/handt/Desktop/finalpjt data/preprocessed_crop/val'\n","\n","# 이미지 데이터 전처리\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,  # 픽셀 값을 0-1 사이로 정규화\n","    rotation_range=40,  # 이미지를 랜덤으로 회전\n","    width_shift_range=0.3,  # 이미지를 수평으로 랜덤 이동\n","    height_shift_range=0.3,  # 이미지를 수직으로 랜덤 이동\n","    shear_range=0.3,  # 이미지를 랜덤으로 시어 변환\n","    zoom_range=0.3,  # 이미지를 랜덤으로 확대/축소\n","    horizontal_flip=True,  # 이미지를 수평으로 랜덤 플립\n","    vertical_flip=True,  # 이미지를 수직으로 랜덤 플립\n","    fill_mode='nearest')  # 변환 후 빈 공간을 채우는 방식\n","\n","validation_datagen = ImageDataGenerator(rescale=1./255) # 검증 데이터, 정규화만 사용\n","\n","# 데이터 로드\n","train_generator = train_datagen.flow_from_directory(\n","    train_dir,\n","    target_size=(224, 224),\n","    batch_size=16,\n","    class_mode='categorical')\n","\n","validation_generator = validation_datagen.flow_from_directory(\n","    validation_dir,\n","    target_size=(224, 224),\n","    batch_size=16,\n","    class_mode='categorical')\n","\n","# 클래스 이름 출력\n","print(\"클래스 이름 (train):\", train_generator.class_indices)\n","print(\"클래스 이름 (validation):\", validation_generator.class_indices)\n","\n","# MobileNetV3 모델 로드\n","base_model = MobileNetV3Large(input_shape=(224, 224, 3),\n","                              include_top=False,\n","                              weights='imagenet')\n","\n","# 모델 맞춤화\n","x = base_model.output\n","x = GlobalAveragePooling2D()(x)\n","x = BatchNormalization()(x)\n","x = Dense(1024, activation='relu')(x)\n","x = Dropout(0.6)(x)  # 드롭아웃 비율 증가\n","x = Dense(512, activation='relu')(x)\n","x = Dropout(0.6)(x)  # 드롭아웃 비율 증가\n","predictions = Dense(len(train_generator.class_indices), activation='softmax')(x)\n","\n","model = Model(inputs=base_model.input, outputs=predictions)\n","\n","# 일부 상위 레이어를 학습 가능하게 설정\n","base_model.trainable = True\n","fine_tune_at = 50\n","for layer in base_model.layers[:fine_tune_at]:\n","    layer.trainable = False\n","\n","# 모델 컴파일\n","model.compile(optimizer=Adam(learning_rate=1e-4),\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","# 콜백 정의\n","reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-7, verbose=1)\n","\n","# 모델 학습\n","history = model.fit(\n","    train_generator,\n","    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n","    epochs=30,\n","    validation_data=validation_generator,\n","    validation_steps=validation_generator.samples // validation_generator.batch_size,\n","    callbacks=[reduce_lr])  # 변경된 콜백\n","\n","# 모델 평가\n","model.evaluate(validation_generator)\n","\n","model.save('saved_model_mobilenetv3_improved.h5')\n","\n"],"metadata":{"id":"-yxAiElmJ70E"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rLe2NRAEipla"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications import InceptionV3\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ReduceLROnPlateau\n","\n","# 데이터 경로 설정\n","train_dir = 'C:/Users/handt/Desktop/finalpjt data/preprocessed_crop/train'\n","validation_dir = 'C:/Users/handt/Desktop/finalpjt data/preprocessed_crop/val'\n","\n","# 이미지 데이터 전처리 설정 (학습 데이터용)\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,  # 픽셀 값을 0-1 사이로 정규화\n","    rotation_range=40,  # 이미지를 랜덤으로 회전\n","    width_shift_range=0.3,  # 이미지를 수평으로 랜덤 이동\n","    height_shift_range=0.3,  # 이미지를 수직으로 랜덤 이동\n","    shear_range=0.3,  # 이미지를 랜덤으로 시어 변환\n","    zoom_range=0.3,  # 이미지를 랜덤으로 확대/축소\n","    horizontal_flip=True,  # 이미지를 수평으로 랜덤 플립\n","    vertical_flip=True,  # 이미지를 수직으로 랜덤 플립\n","    fill_mode='nearest')  # 변환 후 빈 공간을 채우는 방식\n","\n","# 이미지 데이터 전처리 설정 (검증 데이터용)\n","validation_datagen = ImageDataGenerator(rescale=1./255)  # 검증 데이터, 정규화만 사용\n","\n","# 데이터 로드\n","train_generator = train_datagen.flow_from_directory(\n","    train_dir,\n","    target_size=(299, 299),\n","    batch_size=16,\n","    class_mode='categorical')\n","\n","validation_generator = validation_datagen.flow_from_directory(\n","    validation_dir,\n","    target_size=(299, 299),\n","    batch_size=16,\n","    class_mode='categorical')\n","\n","# 클래스 이름 출력\n","print(\"클래스 이름 (train):\", train_generator.class_indices)\n","print(\"클래스 이름 (validation):\", validation_generator.class_indices)\n","\n","# 인셉션V3 모델 로드 (사전 학습된 가중치 사용)\n","base_model = InceptionV3(input_shape=(299, 299, 3),\n","                         include_top=False,  # 최상위 레이어 제외\n","                         weights='imagenet')  # 이미지넷 가중치 사용\n","\n","# 모델 맞춤화 (기본 모델 위에 커스텀 레이어 추가)\n","x = base_model.output\n","x = GlobalAveragePooling2D()(x)  # 전역 평균 풀링 레이어\n","x = BatchNormalization()(x)  # 배치 정규화 레이어\n","x = Dense(1024, activation='relu')(x)  # 완전 연결 레이어 + ReLU 활성화 함수\n","x = Dropout(0.5)(x)  # 드롭아웃 레이어 (과적합 방지)\n","x = Dense(512, activation='relu')(x)  # 또 다른 완전 연결 레이어 + ReLU 활성화 함수\n","x = Dropout(0.5)(x)  # 드롭아웃 레이어 (과적합 방지)\n","predictions = Dense(len(train_generator.class_indices), activation='softmax')(x)  # 출력 레이어 (다중 클래스 분류용 소프트맥스 활성화 함수)\n","\n","# 최종 모델 정의\n","model = Model(inputs=base_model.input, outputs=predictions)\n","\n","# 기본 모델의 일부 레이어를 고정 (학습 불가능하게 설정)\n","base_model.trainable = True\n","fine_tune_at = 172  # 특정 레이어부터 학습 가능하게 설정\n","for layer in base_model.layers[:fine_tune_at]:\n","    layer.trainable = False\n","\n","# 모델 컴파일 (손실 함수와 옵티마이저 설정)\n","model.compile(optimizer=Adam(learning_rate=1e-4),  # Adam 옵티마이저 + 학습률 설정\n","              loss='categorical_crossentropy',  # 손실 함수 설정 (다중 클래스 분류용)\n","              metrics=['accuracy'])  # 평가 지표 설정\n","\n","# 학습률 감소 콜백 정의 (validation loss가 개선되지 않을 때 학습률 감소)\n","reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-7, verbose=1)\n","\n","# 모델 학습\n","history = model.fit(\n","    train_generator,\n","    steps_per_epoch=train_generator.samples // train_generator.batch_size,  # 에포크 당 스텝 수\n","    epochs=30,\n","    validation_data=validation_generator,\n","    validation_steps=validation_generator.samples // validation_generator.batch_size,  # 검증 스텝 수\n","    callbacks=[reduce_lr])  # 콜백 설정\n","\n","# 모델 평가 (검증 데이터)\n","model.evaluate(validation_generator)\n","\n","# 모델 저장\n","model.save('saved_model_inceptionv3_improved.h5')\n"]}],"metadata":{"language_info":{"name":"python"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}